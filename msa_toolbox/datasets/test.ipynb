{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disk1/srishti/miniconda3/envs/srishti/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from text import load_custom_dataset, load_existing_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'text.yelp.yelpDataset'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 4.41k/4.41k [00:00<00:00, 19.3MB/s]\n",
      "Downloading metadata: 100%|██████████| 2.04k/2.04k [00:00<00:00, 18.0MB/s]\n",
      "Downloading readme: 100%|██████████| 6.55k/6.55k [00:00<00:00, 25.6MB/s]\n",
      "Downloading data: 100%|██████████| 196M/196M [00:56<00:00, 3.49MB/s] \n",
      "Generating train split: 100%|██████████| 650000/650000 [00:12<00:00, 53372.99 examples/s]\n",
      "Generating test split: 100%|██████████| 50000/50000 [00:02<00:00, 18992.64 examples/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/mnt/disk1/srishti/MSA_BTP/msa_toolbox/datasets/test.ipynb Cell 2\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B192.168.3.148/mnt/disk1/srishti/MSA_BTP/msa_toolbox/datasets/test.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# initialize class\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B192.168.3.148/mnt/disk1/srishti/MSA_BTP/msa_toolbox/datasets/test.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(yelp)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B192.168.3.148/mnt/disk1/srishti/MSA_BTP/msa_toolbox/datasets/test.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m yelp \u001b[39m=\u001b[39m yelp()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B192.168.3.148/mnt/disk1/srishti/MSA_BTP/msa_toolbox/datasets/test.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m train \u001b[39m=\u001b[39m yelp\u001b[39m.\u001b[39mget_examples(\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/MSA_BTP/msa_toolbox/datasets/text/yelp.py:9\u001b[0m, in \u001b[0;36myelpDataset.__init__\u001b[0;34m(self, dataset_name, data_directory, num_labels, num_attributes, label_probs, data_import_method, config_file, tokenizer, seed)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, dataset_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39myelp\u001b[39m\u001b[39m\"\u001b[39m, data_directory\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, num_labels\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, num_attributes\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, label_probs\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, data_import_method\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mHuggingFace\u001b[39m\u001b[39m'\u001b[39m,  config_file\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, tokenizer\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m , seed \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m----> 9\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(dataset_name, data_directory, num_labels, num_attributes, label_probs, data_import_method, config_file, tokenizer , seed)\n",
      "File \u001b[0;32m~/MSA_BTP/msa_toolbox/datasets/text/CustomDataset.py:57\u001b[0m, in \u001b[0;36mCustomDataset.__init__\u001b[0;34m(self, dataset_name, data_directory, num_labels, num_attributes, label_probs, data_import_method, config_file, tokenizer, seed)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer \u001b[39m=\u001b[39m tokenizer\n\u001b[1;32m     56\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnew_label \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_example \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_examples(split \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     58\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest_example \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_examples(split \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     59\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mval_example \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_examples(split \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mval\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/MSA_BTP/msa_toolbox/datasets/text/CustomDataset.py:80\u001b[0m, in \u001b[0;36mCustomDataset.get_examples\u001b[0;34m(self, split)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_examples(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_read_csv(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_directory, file)))\n\u001b[1;32m     79\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_import_method \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mHuggingFace\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m---> 80\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_examples(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_hugging(split \u001b[39m=\u001b[39;49m split))\n",
      "File \u001b[0;32m~/MSA_BTP/msa_toolbox/datasets/text/CustomDataset.py:123\u001b[0m, in \u001b[0;36mCustomDataset._create_examples\u001b[0;34m(self, lines)\u001b[0m\n\u001b[1;32m    121\u001b[0m     examples\u001b[39m.\u001b[39mappend(Example(i, line[\u001b[39m0\u001b[39m]))\n\u001b[1;32m    122\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m--> 123\u001b[0m     label \u001b[39m=\u001b[39m line[\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49msplit()\n\u001b[1;32m    124\u001b[0m     \u001b[39m# assert len(label) == self.num_labels, \"the number of labels does not match the predicted probs\"\u001b[39;00m\n\u001b[1;32m    125\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(label) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "yelp = load_existing_dataset('yelp')\n",
    "# initialize class\n",
    "print(yelp)\n",
    "yelp = yelp()\n",
    "train = yelp.get_examples('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "yelpDataset._read_hugging() got an unexpected keyword argument 'mode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/mnt/disk1/srishti/MSA_BTP/msa_toolbox/datasets/test.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B192.168.3.148/mnt/disk1/srishti/MSA_BTP/msa_toolbox/datasets/test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#     def __init__(self, dataset_name, data_directory, num_labels=0, num_attributes=0, label_probs=False, data_import_method='tsv', config_file=None, tokenizer=None , seed = None):\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B192.168.3.148/mnt/disk1/srishti/MSA_BTP/msa_toolbox/datasets/test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m yelp \u001b[39m=\u001b[39m yelp(dataset_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39myelp\u001b[39;49m\u001b[39m'\u001b[39;49m, data_directory\u001b[39m=\u001b[39;49m \u001b[39mNone\u001b[39;49;00m , num_labels\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, num_attributes\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, label_probs\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, data_import_method\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mHuggingFace\u001b[39;49m\u001b[39m'\u001b[39;49m, config_file\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, tokenizer\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m , seed \u001b[39m=\u001b[39;49m \u001b[39mNone\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/MSA_BTP/msa_toolbox/datasets/text/yelp.py:9\u001b[0m, in \u001b[0;36myelpDataset.__init__\u001b[0;34m(self, dataset_name, data_directory, num_labels, num_attributes, label_probs, data_import_method, config_file, tokenizer, seed)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, dataset_name, data_directory, num_labels\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, num_attributes\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, label_probs\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, data_import_method\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mHuggingFace\u001b[39m\u001b[39m'\u001b[39m,  config_file\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, tokenizer\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m , seed \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m----> 9\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(dataset_name, data_directory, num_labels, num_attributes, label_probs, data_import_method, config_file, tokenizer , seed)\n",
      "File \u001b[0;32m~/MSA_BTP/msa_toolbox/datasets/text/CustomDataset.py:57\u001b[0m, in \u001b[0;36mCustomDataset.__init__\u001b[0;34m(self, dataset_name, data_directory, num_labels, num_attributes, label_probs, data_import_method, config_file, tokenizer, seed)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer \u001b[39m=\u001b[39m tokenizer\n\u001b[1;32m     56\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnew_label \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_example \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_examples(split \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     58\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest_example \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_examples(split \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     59\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mval_example \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_examples(split \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mval\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/MSA_BTP/msa_toolbox/datasets/text/CustomDataset.py:80\u001b[0m, in \u001b[0;36mCustomDataset.get_examples\u001b[0;34m(self, split)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_examples(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_read_csv(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_directory, file)))\n\u001b[1;32m     79\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_import_method \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mHuggingFace\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m---> 80\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_examples(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_hugging(mode \u001b[39m=\u001b[39;49m split))\n",
      "\u001b[0;31mTypeError\u001b[0m: yelpDataset._read_hugging() got an unexpected keyword argument 'mode'"
     ]
    }
   ],
   "source": [
    "#     def __init__(self, dataset_name, data_directory, num_labels=0, num_attributes=0, label_probs=False, data_import_method='tsv', config_file=None, tokenizer=None , seed = None):\n",
    "yelp = yelp(dataset_name='yelp', data_directory= None , num_labels=5, num_attributes=0, label_probs=False, data_import_method='HuggingFace', config_file=None, tokenizer=None , seed = None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "srishti",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
